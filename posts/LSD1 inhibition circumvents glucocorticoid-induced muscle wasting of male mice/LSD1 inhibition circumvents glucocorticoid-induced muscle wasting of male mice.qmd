---
title: "Fig 7d -- LSD1 inhibition circumvents glucocorticoid-induced muscle wasting of male mice"
author: "Jeff Walker"
date: '25 June 2024'
date-modified: "`r Sys.Date()`"
categories: ["p-values", "multiple testing", "generalized linear model", "pseudoreplication", "analysis flag"]
description: "The researchers analyzed figure 7b using one-way ANOVA with Tukey adjustment. The data (RNA levels) have a typical count distribution with right skew and variances that increase with the mean. The example is a good one to talk about p-values in bench biology. Two decisions in the analysis result in conservative p-values: 1) The ANOVA model has less power than a generalized linear model (GLM) that explicitly models a count distribution, and 2) The Tukey correction, which isn't justified here. A third decision results in liberal p-values: the researchers analyzed the two technical replicates per mouse as if they were independent."
draft: true
format: 
  html: 
    toc: true 
    toc-location: right
execute: 
  message: false
  warning: false
editor_options: 
  chunk_output_type: inline
freeze: false
---

## Vital info

Data From: [Cai, Q., Sahu, R., Ueberschlag-Pitiot, V., Souali-Crespo, S., Charvet, C., Silem, I., ... & Duteil, D. (2024). LSD1 inhibition circumvents glucocorticoid-induced muscle wasting of male mice. Nature Communications, 15(1), 3563.](https://www.nature.com/articles/s41467-024-47846-9){target="_blank"}

Fig: 7d [download data](../../data from/LSD1 inhibition circumvents glucocorticoid-induced muscle wasting of male mice/41467_2024_47846_MOESM4_ESM.xlsx){target="_blank"}

key words: 

Published methods: one-way ANOVA with Tukey adjustment

Design: Completely Randomized Design with subsampling (CRDS)

Response: mRNA level

Key learning concepts: not adjusting for multiple p-values

More info: [Chapter 16 Models for non-independence -- linear mixed models](https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/lmm){target="_blank"}

## The Experiment

Dexamethasone (DEX) is a synthetic glucocortacoid hormone used to treat inflammation and chronic autoimmune diseases but it also stimulates muscle atrophy. The authors are investigating the role of interactions between Lysine-specific demethylase 1 (LSD1) and the glucocortacoid recepter (GCR) in the development of muscle atrophy.

Earlier experiments presented in the paper show evidence that atrophy is mediated by a LSD1/GCR complex that regulates genes related to atrophy and other pathways. For this experiment, mice were treated with a combination of DEX and the LSD1-specific inhibitor CC-90011. Here the researchers are looking at the effect of the different treatment combinations on RNA expression of genes related to the ubiquitin-proteasome system (Fbxo32, Trim63) and the autophagy system (Atg7, Becn1, Bnip3).

Treatment levels

1. Vehicle (Dex-/CC-) Expected to have low levels of target gene expression
2. Dex (Dex+/CC-)     Positive control. Expected to have elevated levels of target gene expression relative to vehicle
3. CC (Dex-/CC+)      Important negative control. We expect this to be similar to Vehicle. If it is not, we need the interaction.
4. DEX+CC (Dex+/CC+)  If LSD1 works with the GCR as expected, then we expect these levels to be lower than Dex+/CC- but how much depends on CC concentration.

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# wrangling packages
library(here) # here makes a project transportable
library(janitor) # clean_names
library(readxl) # read excel, duh!
library(writexl) # write excel, duh!
library(data.table) # magical data frames
library(magrittr) # pipes
library(stringr) # string functions
library(forcats) # factor functions

# analysis packages
library(emmeans) # the workhorse for inference
library(nlme) # gls and some lmm
library(lme4) # linear mixed models
library(lmerTest) # linear mixed model inference
library(afex) # ANOVA linear models
library(glmmTMB) # generalized linear models
library(MASS) # negative binomial and some other functions
library(car) # model checking and ANOVA
library(DHARMa) # model checking
library(mvtnorm)
library(MHTdiscrete) # sidak

# graphing packages
library(ggsci) # color palettes
library(ggpubr) # publication quality plots
library(ggforce) # better jitter
library(cowplot) # combine plots
library(knitr) # kable tables
library(kableExtra) # kable_styling tables

# ggplot_the_model.R packages not loaded above
library(insight)
library(lazyWeave)

# use here from the here package
here <- here::here
# use clean_names from the janitor package
clean_names <- janitor::clean_names
# use transpose from data.table
transpose <- data.table::transpose

# load functions used by this text written by me
# ggplot_the_model.R needs to be in the folder "R"
# if you didn't download this and add to your R folder in your
# project, then this line will cause an error
source_path <- here("R", "ggplot_the_model.R")
source(source_path)
source_path <- here("R", "ggptm.R")
source(source_path)

data_folder <- "data from"
image_folder <- "images"
output_folder <- "output"
```

## Import and Wrangle


```{r fig-7d-import, message=FALSE, warning=FALSE}
data_from <- "LSD1 inhibition circumvents glucocorticoid-induced muscle wasting of male mice"
file_name <- "41467_2024_47846_MOESM4_ESM.xlsx"
file_path <- here(data_folder, data_from, file_name)

read7d <- function(range_val = "B3:E13", label_val = "Fbxo32"){
  fig7d_part <- read_excel(file_path,
                    sheet = "Fig. 7d",
                    range = range_val,
                    col_names = TRUE) |>
  data.table() |>
    melt(variable.name = "excel_label", value.name = "y")
  # un-normalize count by multiplying by 10^6
  fig7d_part[, y := as.integer(y * 10^6)]
  setnames(fig7d_part, old = "y", new = label_val)
  fig7d_part[, mouse_id := paste0("mouse_", .I)]
  return(fig7d_part)
}
fig7d <- read7d(range_val = "B3:E13", label_val = "Fbxo32")
fig7d <- merge(fig7d,
               read7d(range_val = "B16:E26", label_val = "Trim63"),
               by = c("excel_label", "mouse_id"))
fig7d <- merge(fig7d,
               read7d(range_val = "B29:E39", label_val = "Atg7"),
               by = c("excel_label", "mouse_id"))
fig7d <- merge(fig7d,
               read7d(range_val = "B42:E52", label_val = "Becn1"),
               by = c("excel_label", "mouse_id"))
fig7d <- merge(fig7d,
               read7d(range_val = "B55:E65", label_val = "Bnip3"),
               by = c("excel_label", "mouse_id"))

# remove the missing count
fig7d <- na.omit(fig7d)

# better treatment labels than in excel file
fig7d[excel_label == "Ctrl Oil", treatment := "Vehicle"]
fig7d[excel_label == "DEX", treatment := "DEX"]
fig7d[excel_label == "DEX+CC-90011", treatment := "DEX+CC"]
fig7d[excel_label == "CC-90011", treatment := "CC"]
fig7d[, treatment := factor(treatment, levels = unique(fig7d$treatment))]

# split treatment into two factors
fig7d[treatment == "Vehicle", dex := "Dex_neg"]
fig7d[treatment == "Vehicle", cc := "CC_neg"]
fig7d[treatment == "DEX", dex := "Dex_pos"]
fig7d[treatment == "DEX", cc := "CC_neg"]
fig7d[treatment == "DEX+CC", dex := "Dex_pos"]
fig7d[treatment == "DEX+CC", cc := "CC_pos"]
fig7d[treatment == "CC", dex := "Dex_neg"]
fig7d[treatment == "CC", cc := "CC_pos"]

fig7d[, dex := factor(dex, levels = c("Dex_neg", "Dex_pos"))]
fig7d[, cc := factor(cc, levels = c("CC_neg", "CC_pos"))]


file_out_name <- "LSD1 inhibition circumvents glucocorticoid-induced muscle wasting of male mice.xlsx"
fileout_path <- here(data_folder, data_from, file_out_name)
write_xlsx(fig7d, fileout_path)

```

## Does the unstandardization matter

```{r}
Fbxo32_4 <- fig7d[, Fbxo32]/10^6 * 10^4
m1 <- lm(Fbxo32 ~ treatment, data = fig7d)
m2 <- lm(Fbxo32_4 ~ treatment, data = fig7d)
coef(summary(m1))
coef(summary(m2))
```
```{r}
m1 <- lm(Fbxo32 ~ treatment, data = fig7d)
```


## 1. The reported p-values are conservative (a bit on the "multiple testing" problem), or not!

The researchers reported Tukey-adjusted p-values. The Tukey method adjusts for the number of tests in a "family" of tests, where a family is the set of tests that answer one question. The researchers follow the norm in bench bio and choose the whole set of six contrasts as the family. This would answer a question such as: "if we were to create these combinations, would we find any difference between at least on pair?", which isn't a very interesting question.

The researchers are focused on a much more specific question and at least two more questions, both related to controls:

1. Family 1: Is there evidence that CC attenuates DEX-induced expression? There is only one test in this family: DEX+CC - DEXI. This is the focal family.
2. Family 2: Is there evidence that DEX increase expression levels, as expected? This is the "positive control" family. There is only one test in this family: DEX - Vehicle.
3. Family 3: What is the effect of CC alone? This is "negative control" family. Without DEX-induced elevated express, we would expect this response to be similar to Vehicle. There is only one test in this family: CC - Vehicle.

What about the interaction effect? The contrast (DEX+CC - DEX) is the focal contrast *if there is no effect of CC alone*. We could look at the CC alone effect (CC - Vehicle) and if it is sufficiently small, use (DEX+CC - DEX) as the focal contrast. Of course "sufficiently small" has a subjective bright line. The statistically correct way to address this is to compare the effect of CC with DEX (the focal contrast) to the effect of CC without DEX (CC - Vehicle). This comparison is the interaction effect. So we'll add the interaction contrast as a 4th family, which we should think of as replacing the focal contrast (Family 1) and not "in addition to" the three families. But, I'll compute both. Regardless, for these data, I think most researchers would agree that CC - Vehicle is sufficiently small that we can use the DEX+CC - DEX comparison without issue.

So we have three p-values that we care about and each is from a different family, so there is no justification for p-value adjustment for multiple tests. This would make the reported p-values conservative. In general, if I wanted to be more conservative, in order to avoid research time and waste, I'd simply make my "alpha" smaller, such as 0.01 or 0.005 instead of using more conservative tests like a Tukey p-value adjustment, since the conservative alpha doesn't depend on things like number of tests in a family.


```{r p-value-adjustment}
# the researcher's analysis
m0 <- lm(Fbxo32 ~ treatment, data = fig7d)
m0_emm <- emmeans(m0, c("treatment"))
m0_pairs <- contrast(m0_emm,
                     method = "revpairwise",
                     adjust = "tukey") |>
  summary(infer = TRUE)

# the analysis only comparing the three families of tests that we care about
veh = c(1, 0, 0, 0)
dex = c(0, 1, 0, 0)
dex_cc = c(0, 0, 1, 0) # note the wonky ordering in fig 7d
cc = c(0,0,0,1)
focal_contrasts = list(
  "dex" = dex - veh,
  "cc" = cc - veh,
  "dex+cc - dex" = dex_cc - dex,
  "interaction" = (dex_cc - dex) - (cc - veh)
)
m1 <- lm(Fbxo32 ~ treatment, data = fig7d)
m1_emm <- emmeans(m1, c("treatment"))
m1_pairs <- contrast(m1_emm,
                     method = focal_contrasts,
                     adjust = "none") |>
  summary(infer = TRUE)

contrast_table <-
  rbind(m0_pairs, m1_pairs)
contrast_table |>
  kable(digits = 4) |>
  kable_styling() |>
  pack_rows("Adjusted", 1, 6) |>
  pack_rows("Non-adjusted", 7, 10)
```

The top table contains the six Tukey-adjusted p-values reported by the researchers. The bottom table contains the unadjusted values of only the contrasts of interest. The adjusted *p*-value for the focal contrast DEX+CC - DEX is 0.023 while the unadjusted value is 0.0046.

The p-value of the interaction is 0.035 -- note that it's effect size is very similar to that of the DEX+CC - DEX but the p-value is bigger because the SE of an interaction is bigger than the SE of a main contrast (because the interaction is a function of 4 means and not just 2). Using the interaction p-value is not just statistically correct, it is more conservative.

## 2. For these data, a Generalized Linear Model will have more power than the linear model/ANOVA.

Several simulation experiments have shown that *t*-tests and linear models/ANOVA generally work well for count data, where "work well" means that Type I errors aren't too elevated and Power is relatively high. However, the simulations also show that negative-binomial Generalized Linear Models do better at controlling Type I error and have higher power, relative to *t*-tests/linear models/ANOVA models. For any one experiment, using a *t*-test/linear model/ANOVA model will have little consequence but over many, many experiments, we would expect to have fewer false negatives and positives if we use GLMs. That said, I prefer the GLM for two additional reasons: 1) The effect is a multiple of the reference, which is a really meaningful way of comparing responses (for example, looking at the table below, the effect is 6.5, meaning the expression level is 6.5 times larger than that of Vehicle), and 2) the CIs of the means are asymmetric, which reflects the skewed distribution of the data. This also avoids absurd CIs such as a negative lower bound (counts can't be negative!).

```{r, warning=FALSE}
# the original analysis in m0, m0_emm, and m0_pairs are computed above

m2 <- glm.nb(Fbxo32 ~ treatment, data = fig7d)
m2_emm <- emmeans(m2, c("treatment"), type = "response")
m2_pairs <- contrast(m2_emm,
                     method = "revpairwise",
                     adjust = "tukey") |>
  summary(infer = TRUE)

m2_pairs <- m2_pairs[, -7]
colnames(m2_pairs) <- colnames(m0_pairs)
contrast_table <-
  rbind(m0_pairs, m2_pairs)
contrast_table |>
  kable(digits = 4) |>
  kable_styling() |>
  pack_rows("LM/ANOVA", 1, 6) |>
  pack_rows("GLM", 7, 12)

```
The top table contains the six Tukey-adjusted p-values reported by the researchers. The bottom table contains the six Tukey-adjusted p-values using a negative-binomial Generalized Linear Model (a useful model for count data). The focal-contrast *p*-value for the linear model/ANOVA and the GLM are similar (0.023 and 0.0347). 

## Putting #1 and #2 together

```{r, warning = FALSE}

m2_pairs_focal <- contrast(m2_emm,
                     method = focal_contrasts,
                     adjust = "none") |>
  summary(infer = TRUE)
m2_pairs_focal <- m2_pairs_focal[, -7]
colnames(m2_pairs_focal) <- colnames(m0_pairs)
contrast_table <-
  rbind(m0_pairs, m2_pairs_focal)
contrast_table |>
  kable(digits = 4) |>
  kable_styling() |>
  pack_rows("LM/ANOVA adjusted", 1, 6) |>
  pack_rows("GLM not adjusted", 7, 10)

```

The top table contains the six Tukey-adjusted p-values reported by the researchers. The bottom table contains the four unadjusted p-values using a negative-binomial Generalized Linear Model.

## Let's plot the model for all genes

```{r warning = FALSE}
get_model_result <- function(gene_i){
  model_formula <- paste(gene_i, "~ dex * cc") |>
    as.formula()
  m1 <- glm.nb(model_formula, data = fig7d)
  m1_emm <- emmeans(m1, specs = c("dex", "cc"), type = "response")
  m1_pairs <- contrast(m1_emm,
                       method = "revpairwise",
                       simple = "each",
                       combine = TRUE,
                       adjust = "none") |>
    summary(infer = TRUE)
  return(list(m1 = m1, m1_emm = m1_emm, m1_pairs = m1_pairs))
}

res1 <- get_model_result("Fbxo32")
gg1 <- plot_response(res1$m1, res1$m1_emm, res1$m1_pairs, palette = "pal_okabe_ito_blue")
res2 <- get_model_result("Trim63")
gg2 <- plot_response(res2$m1, res2$m1_emm, res2$m1_pairs, palette = "pal_okabe_ito_blue")
res3 <- get_model_result("Atg7")
gg3 <- plot_response(res3$m1, res3$m1_emm, res3$m1_pairs, palette = "pal_okabe_ito_blue")
res4 <- get_model_result("Becn1")
gg4 <- plot_response(res4$m1, res4$m1_emm, res4$m1_pairs, palette = "pal_okabe_ito_blue")
res5 <- get_model_result("Bnip3")
gg5 <- plot_response(res5$m1, res5$m1_emm, res5$m1_pairs, palette = "pal_okabe_ito_blue")

plot_grid(gg1, gg2, gg3, gg4, gg5, nrow = 3)
gg1
gg2
gg3
gg4
gg5
```


```{r}
veh = c(1, 0, 0, 0)
dex = c(0, 1, 0, 0)
dex_cc = c(0, 0, 1, 0) # note the wonky ordering in fig 7d
cc = c(0,0,0,1)
focal_contrasts = list(
  "dex" = dex - veh,
  "cc" = cc - veh,
  "dex+cc - dex" = dex_cc - dex,
  "interaction" = (dex_cc - dex) - (cc - veh)
)
m1 <- glm.nb(Fbxo32 ~ treatment, data = fig7d)
m1_emm <- emmeans(m1, c("treatment"))
m1_pairs <- contrast(m1_emm,
                     method = focal_contrasts,
                     adjust = "none") |>
  summary(infer = TRUE)

m1b_pairs <- contrast(m1_emm,
                      method = "revpairwise",
                      adjust = "none") |>
  summary(infer = TRUE)

m1c <- glm.nb(Fbxo32 ~ dex * cc, data = fig7d)
m1c_emm <- emmeans(m1c, c("dex", "cc"))
m1c_pairs <- contrast(m1c_emm,
                      method = "revpairwise",
                      simple = "each",
                      combine = TRUE,
                      adjust = "none") |>
  summary(infer = TRUE)

m1_pairs
coef(summary(m1c))

contrast_table <-
  rbind(m1_pairs, m1b_pairs, m1c_pairs)
contrast_table |>
  kable(digits = 4) |>
  kable_styling() |>
  pack_rows("manual", 1, 4) |>
  pack_rows("flat", 5, 10) |>
  pack_rows("2x2", 11, 14)

```


