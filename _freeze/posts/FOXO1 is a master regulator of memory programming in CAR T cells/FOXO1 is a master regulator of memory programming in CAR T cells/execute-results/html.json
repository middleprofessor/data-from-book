{
  "hash": "fa11531a7b5967bc65155e0338860969",
  "result": {
    "markdown": "---\ntitle: \"Fig 4h -- FOXO1 is a master regulator of memory programming in CAR T cells\"\nauthor: \"Jeff Walker\"\ndate: '17 May 2024'\ndate-modified: \"2024-05-22\"\ncategories: ['technical replicates', 'pseudoreplication', 'nested', 'CRDS', 'analysis flag']\ndescription: \"Fig 4h contains thousands of technical replicates. Technical replicates should not be analyzed as if they were randomly assigned to one of the experimental treatments. They weren't. The resulting p-value is junk.\"\nformat: \n  html: \n    toc: true \n    toc-location: right\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\nfreeze: auto\n---\n\n\n![Fig 4h](../../figs/FOXO1 is a master regulator of memory programming in CAR T cells/fig4h.png)\n\n## Vital info\n\nData From: [Doan, Alexander E., et al. \"FOXO1 is a master regulator of memory programming in CAR T cells.\" Nature (2024): 1-8.](https://www.nature.com/articles/s41586-024-07300-8){target=\"_blank\"}\n\nFig: 4h [download data](../../data from/FOXO1 is a master regulator of memory programming in CAR T cells/41586_2024_7300_MOESM9_ESM.xlsx){target=\"_blank\"} (note the tab is incorrectly labeled Figure 4i\")\n\nkey words: pseudoreplication, technical replicates, nested, simulation, confidence interval\n\nPublished methods: Wilcoxan rank-sum test (non-parametric *t*-test alternative)\n\nDesign: 2 x 1 CRDS\n\nResponse: per-cell module score, which is a combined expression level for a specified gene set.\n\nKey learning concepts: Pseudoreplication. Nested design.\n\nMore info: [Chapter 16 Models for non-independence -- linear mixed models](https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/lmm){target=\"_blank\"}\n\nQuick learning explanation: Pseudoreplication is the analysis of subsampled (technical) replicates as if they were experimental replicates. This is a violation of the assumption of independence of errors. Nested data are measures within a discrete unit or a hierarchy of units, for example technical replicates within a tumor within a mouse.\n\nComments: The researchers measured gene set expression levels in thousands of cells from mice assigned to two treatments, with five mice in each treatment. Cells from all mice within a treatment were pooled. The *t*-test assumes independent errors of all expression level scores but the scores of the different cells within a mouse are not independent -- these are technical replicates or subsampled replicates -- so the scores will be clustered (a clinical research term) or batched (a bench biology term) where each mouse is the cluster or batch.\n\nSingle-cell experiments of this design are effectively not worth the time and money because small *p*-values are almost guaranteed **even if there is no true difference in expression level**. That is, we are extremely unlikely to reliably learn anything. More generally, this design will result in extremely small *p*-values for very small, and possibly biologically meaningless, effect sizes. When this happens, researchers are likely to pursue research paths with trivial consequences for mouse health.\n\nAlways Remember: A *p*-value is a measure of evidence against the null model and not a measure of the truth of an effect. In bench biology, a *p*-value is best used to aid decision making -- with a small *p*-value we can act as if an effect exists and pursue further experiments. If there is a high cost to these further experiments, we want a really small *p*-value (say < 0.01) to act. If there is little cost to these further experiments we can use a larger *p*-value (say, < 0.1) to act.\n\n## Pseudoreplication red flag\n\nLook at the figure!\n\nThe typical number of experimental replicates in bench biology is 3-8 with occasional replications up to about 30. The mere presence of many 10s or 100s of points per treatment is a red flag for pseudoreplication.\n\n## Background\n\nCAR T cells are engineered immune cells that attack tumor cells. A common problem with CAR T cell treatment is the tumor cell killing activity diminishes over time. The researchers are interested in modifying the CAR T cells to maintain killing activity. FOX01 is a transcription factor that regulates genes that control the memory properties of T cells.\n\n## The experiment\n\nTreatment levels 1. tNGFR (control). This is truncated NGFR 2. FOX01_OE (treatment). This is a modification that overexpresses FOX01.\n\nUsing mice with osteosarcoma, five mice were infused with tNGFR CAR T cells and five mice were infused with FOX01_OE CAR T cells. Tumors were collected and CAR T cells were isolated and pooled across the five mice within a treatment for single-cell RNA sequencing.\n\nThe response is a per-cell module score, which is a combined expression level for a specified gene set, in log10 units. \n\n## The statistical issue\n\nThe treatments were not randomized to cell but to mouse, so the scores within mouse are not independent of each other because the cells within a tumor within a mouse share tumor environmental factors that cells within a tumor in other mice do not share.\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE)\n\n# wrangling packages\nlibrary(here) # here makes a project transportable\nlibrary(janitor) # clean_names\nlibrary(readxl) # read excel, duh!\nlibrary(writexl) # write excel, duh!\nlibrary(data.table) # magical data frames\nlibrary(magrittr) # pipes\nlibrary(stringr) # string functions\nlibrary(forcats) # factor functions\n\n# analysis packages\nlibrary(emmeans) # the workhorse for inference\nlibrary(nlme) # gls and some lmm\nlibrary(lme4) # linear mixed models\nlibrary(lmerTest) # linear mixed model inference\nlibrary(afex) # ANOVA linear models\nlibrary(glmmTMB) # generalized linear models\nlibrary(MASS) # negative binomial and some other functions\nlibrary(car) # model checking and ANOVA\nlibrary(DHARMa) # model checking\nlibrary(mvtnorm)\n\n# graphing packages\nlibrary(ggsci) # color palettes\nlibrary(ggpubr) # publication quality plots\nlibrary(ggforce) # better jitter\nlibrary(cowplot) # combine plots\nlibrary(knitr) # kable tables\nlibrary(kableExtra) # kable_styling tables\n\n# ggplot_the_model.R packages not loaded above\nlibrary(insight)\nlibrary(lazyWeave)\n\n# use here from the here package\nhere <- here::here\n# use clean_names from the janitor package\nclean_names <- janitor::clean_names\n# use transpose from data.table\ntranspose <- data.table::transpose\n\n# load functions used by this text written by me\n# ggplot_the_model.R needs to be in the folder \"R\"\n# if you didn't download this and add to your R folder in your\n# project, then this line will cause an error\nsource_path <- here(\"R\", \"ggplot_the_model.R\")\nsource(source_path)\n\ndata_folder <- \"data from\"\nimage_folder <- \"images\"\noutput_folder <- \"output\"\n```\n:::\n\n\n\n## Import, wrangle, and summarize\n\nImport and wrangle using data.table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_from <- \"FOXO1 is a master regulator of memory programming in CAR T cells\"\nfile_name <- \"41586_2024_7300_MOESM9_ESM.xlsx\"\nfile_path <- here(data_folder, data_from, file_name)\n\nfig4h_wide <- read_excel(file_path,\n                    sheet = \"Figure 4i\",\n                    range = \"A4:h7659\",\n                    col_names = TRUE) |>\n  data.table()\nsetnames(fig4h_wide,\n         old = names(fig4h_wide),\n         new = c(\"tNGFR_teff\", \"FOXO1OE_teff\", \"x1\",\n                 \"tNGFR_trm\", \"FOXO1OE_trm\", \"x2\",\n                 \"tNGFR_bulk\", \"FOXO1OE_bulk\"))\nfig4h_wide <- fig4h_wide[, .SD, .SDcols = c(\"tNGFR_teff\", \"FOXO1OE_teff\",\n                                            \"tNGFR_trm\", \"FOXO1OE_trm\",\n                                            \"tNGFR_bulk\", \"FOXO1OE_bulk\")]\nfig4h <- melt(fig4h_wide,\n             measure.vars = list(c(\"tNGFR_teff\", \"FOXO1OE_teff\"),\n                                 c(\"tNGFR_trm\", \"FOXO1OE_trm\"),\n                                 c(\"tNGFR_bulk\", \"FOXO1OE_bulk\")),\n             variable.name = \"treatment_code\",\n             value.name = c(\"teff\", \"trm\", \"bulk\"))\nfig4h[, treatment := ifelse(treatment_code == 1, \"tNGFR\", \"FOXO1OE\") |>\n       factor(levels = c(\"tNGFR\", \"FOXO1OE\"))]\n```\n:::\n\n\nSummarize data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfig4h_long <- melt(fig4h,\n                  id.vars = \"treatment\",\n                  measure.vars = c(\"teff\", \"trm\", \"bulk\"),\n                  variable.name = \"response\",\n                  value.name = \"score\")\nfig4h_summary <- fig4h_long[!is.na(score), .(N = .N,\n                                mean = mean(score, na.rm = TRUE),\n                              sd = sd(score, na.rm = TRUE)),\n                          by = .(treatment, response)]\nfig4h_summary |>\n  kable(caption = \"Summary data of three response measures\",\n        digits = c(1,1,0,3,3)) |>\n  kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Summary data of three response measures</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> treatment </th>\n   <th style=\"text-align:left;\"> response </th>\n   <th style=\"text-align:right;\"> N </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> tNGFR </td>\n   <td style=\"text-align:left;\"> teff </td>\n   <td style=\"text-align:right;\"> 7346 </td>\n   <td style=\"text-align:right;\"> 0.280 </td>\n   <td style=\"text-align:right;\"> 0.332 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FOXO1OE </td>\n   <td style=\"text-align:left;\"> teff </td>\n   <td style=\"text-align:right;\"> 7655 </td>\n   <td style=\"text-align:right;\"> 0.499 </td>\n   <td style=\"text-align:right;\"> 0.327 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tNGFR </td>\n   <td style=\"text-align:left;\"> trm </td>\n   <td style=\"text-align:right;\"> 7346 </td>\n   <td style=\"text-align:right;\"> 0.031 </td>\n   <td style=\"text-align:right;\"> 0.202 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FOXO1OE </td>\n   <td style=\"text-align:left;\"> trm </td>\n   <td style=\"text-align:right;\"> 7655 </td>\n   <td style=\"text-align:right;\"> 0.105 </td>\n   <td style=\"text-align:right;\"> 0.193 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tNGFR </td>\n   <td style=\"text-align:left;\"> bulk </td>\n   <td style=\"text-align:right;\"> 7346 </td>\n   <td style=\"text-align:right;\"> 0.379 </td>\n   <td style=\"text-align:right;\"> 0.116 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FOXO1OE </td>\n   <td style=\"text-align:left;\"> bulk </td>\n   <td style=\"text-align:right;\"> 7655 </td>\n   <td style=\"text-align:right;\"> 0.448 </td>\n   <td style=\"text-align:right;\"> 0.104 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Statistical analysis to get effect sizes (but no inference)\n\nHere I fit a naïve linear model (*t*-test equivalent) ignoring nesting to get the effect size (fold change) and relative effects size (Cohen's D).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_teff <- lm(teff ~ treatment, data = fig4h)\n#coef(summary(m1_teff))\nstats_table <- data.table(\n  Response = \"TEFF\",\n  Difference = coef(summary(m1_teff))[2, 1],\n  \"Fold Change\" = 10^coef(summary(m1_teff))[2, 1],\n  Cohen = coef(summary(m1_teff))[2, 1]/summary(m1_teff)$sigma\n)\n\nm1_trm <- lm(trm ~ treatment, data = fig4h)\nstats_table <- rbind(stats_table,\n                     data.table(\n                       Response = \"TRM\",\n                       Difference = coef(summary(m1_trm))[2, 1],\n                       \"Fold Change\" = 10^coef(summary(m1_trm))[2, 1],\n                       Cohen = coef(summary(m1_trm))[2, 1]/summary(m1_trm)$sigma\n                     )\n)\n\nm1_bulk <- lm(bulk ~ treatment, data = fig4h)\nstats_table <- rbind(stats_table,\n                     data.table(\n                       Response = \"Bulk\",\n                       Difference = coef(summary(m1_bulk))[2, 1],\n                       \"Fold Change\" = 10^coef(summary(m1_bulk))[2, 1],\n                       Cohen = coef(summary(m1_bulk))[2, 1]/summary(m1_bulk)$sigma\n                     )\n)\nstats_table |>\n  kable(digits = c(1,3,2,2)) |>\n  kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Response </th>\n   <th style=\"text-align:right;\"> Difference </th>\n   <th style=\"text-align:right;\"> Fold Change </th>\n   <th style=\"text-align:right;\"> Cohen </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> TEFF </td>\n   <td style=\"text-align:right;\"> 0.219 </td>\n   <td style=\"text-align:right;\"> 1.65 </td>\n   <td style=\"text-align:right;\"> 0.66 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRM </td>\n   <td style=\"text-align:right;\"> 0.075 </td>\n   <td style=\"text-align:right;\"> 1.19 </td>\n   <td style=\"text-align:right;\"> 0.38 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Bulk </td>\n   <td style=\"text-align:right;\"> 0.069 </td>\n   <td style=\"text-align:right;\"> 1.17 </td>\n   <td style=\"text-align:right;\"> 0.63 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThese fold-changes seem smallish, at least relative to fold changes for single genes (and not gene sets) that I typically see while scanning the bench biology literature. That said, what is important is not the fold change relative to other genes or gene sets but the biological consequences of the observed fold changes, a a kind of question that I'd love to see addressed more in the bench biology literature.\n\n## What we'd like to do but cannot\n\nIf the cells for each mouse within a treatment hadn't been pooled OR if we had the mouse ID for each cell, then we would simply average the scores over all cells within a mouse and use a *t*-test using the five values for tNGFR and five values for FOX01_OE.\n\n## A conservative attempt at inference using resampling\n\nThe experiment has five independent values per treatment. Assuming there is no variation in the response between mice (that is, all variation is among cells within a mouse), we can get a statistically-valid *p*-value by randomly sampling five values of each treatment and doing a *t*-test. This *p*-value will be very unstable due to the large variation within a treatment level relative to the difference between treatments, so a better method is to use the within-treamtent values as the sampling distribution.\n\nThe algorithm:\n\n1. Sample five values of each treatment, with replacement\n2. Do a *t*-test\n3. Save the *t*test statistic\n4. Save the effect (the difference in treatment means)\n5. Repeat 1-4 2000 times\n\nThe 95% confidence limits of the difference in means is computed as the 2.5 and 97.5 percentiles of the set of effects\n\nThe *p*-value is computed as the number of *t*-values less than zero (this is a one-sided test).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nn_reps <- 2000\nd_out <- matrix(as.numeric(NA), nrow = n_reps, ncol = 3)\nt_out <- matrix(as.numeric(NA), nrow = n_reps, ncol = 3)\ncolnames(d_out) <- c(\"TEFF\", \"TRM\", \"Bulk\")\ncolnames(t_out) <- c(\"TEFF\", \"TRM\", \"Bulk\")\n\ntngfr_teff <- fig4h[treatment == \"tNGFR\", teff] |>\n  na.omit()\nfox_teff <- fig4h[treatment == \"FOXO1OE\", teff] |>\n  na.omit()\ntngfr_trm <- fig4h[treatment == \"tNGFR\", trm] |>\n  na.omit()\nfox_trm <- fig4h[treatment == \"FOXO1OE\", trm] |>\n  na.omit()\ntngfr_bulk <- fig4h[treatment == \"tNGFR\", bulk] |>\n  na.omit()\nfox_bulk <- fig4h[treatment == \"FOXO1OE\", bulk] |>\n  na.omit()\n\nfor(i in 1:n_reps){\n  t_teff <- t.test(sample(tngfr_teff, 5, replace = TRUE),\n                      sample(fox_teff, 5, replace = TRUE),\n                      equal.var = TRUE)\n  t_trm <- t.test(sample(tngfr_trm, 5, replace = TRUE),\n                      sample(fox_trm, 5, replace = TRUE),\n                      equal.var = TRUE)\n  t_bulk <- t.test(sample(tngfr_bulk, 5, replace = TRUE),\n                      sample(fox_bulk, 5, replace = TRUE),\n                      equal.var = TRUE)\n  d_out[i, \"TEFF\"] <- t_teff$estimate |> diff()\n  d_out[i, \"TRM\"] <- t_trm$estimate |> diff()\n  d_out[i, \"Bulk\"] <- t_bulk$estimate |> diff()\n\n  t_out[i, \"TEFF\"] <- -t_teff$statistic\n  t_out[i, \"TRM\"] <- -t_trm$statistic\n  t_out[i, \"Bulk\"] <- -t_bulk$statistic\n\n}\n\nci <- function(x){\n  return(quantile(x, c(0.025, 0.975)))\n}\n\nci_df <- apply(d_out, 2, ci)\nci_table <- data.table(\n  Response = colnames(ci_df),\n  t(ci_df)\n)\nci_table |>\n  kable(caption = \"95% CIs of each response\",\n        digits = c(2, 2, 2)) |>\n  kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>95% CIs of each response</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Response </th>\n   <th style=\"text-align:right;\"> 2.5% </th>\n   <th style=\"text-align:right;\"> 97.5% </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> TEFF </td>\n   <td style=\"text-align:right;\"> -0.20 </td>\n   <td style=\"text-align:right;\"> 0.64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRM </td>\n   <td style=\"text-align:right;\"> -0.17 </td>\n   <td style=\"text-align:right;\"> 0.31 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Bulk </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n   <td style=\"text-align:right;\"> 0.20 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nlt0 <- function(x){\n  return(sum(x < 0))\n}\n\np <- apply(t_out, 2, lt0)/n_reps\np_table <- data.table(\n  Response = names(p),\n  p = p)\np_table |>\n  kable(caption = \"Resampled p-values of each response\",\n        digits = 2) |>\n  kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Resampled p-values of each response</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Response </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> TEFF </td>\n   <td style=\"text-align:right;\"> 0.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRM </td>\n   <td style=\"text-align:right;\"> 0.27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Bulk </td>\n   <td style=\"text-align:right;\"> 0.14 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nA Confidence Interval is the set of bounds of the range of values that is consistent with the data and is useful to model the biological consequences of the low end vs. the high end.\n\nThe simplest use of a CI is to to simply use it as a binary *p*-value -- if the CI includes zero, the *p*-value is not significant at the level of the CI (here, this is 5%). So, using the CI, we can infer that the *p*-value for each of the responses is not significant if we use 5% as our level. The directly measured *p*-values for all three responses are also not significant at this level and suggest we act as if there is no effect.\n\n## Better *p*-values...kinda\n\nThe resampling tests above are conservative because they use the total variance to estimate the *t*-value. What we really want is the variance among the mice, since this is the level that the treatment was applied, and this variance will be smaller than the total variance, so the denominator of the *t*-value will be smaller, the *t*-value will be bigger, and the *p*-value smaller! And we have a huge sample size to estimate this variance precisely.\n\nThe problem is, we don't know the variance among the mice because the cells from mice within a treatment were pooled. So let's model this and computed expected *p*-values across a range of among-mice variance. The amount of among-mice variance relative to the total variance (among-mice + among-cell) is the **intraclass correlation coefficient** (ICC), which ranges between zero and one. The further the ICC is from zero, the more correlated (dependent) the errors and the wrong the inference using a naïve test like that of the researchers.\n\nAlgorithm:\n\n1. Start with the lowest ICC in a pre-specified list of ICCs that range between 0 and 1\n2. Use the observed total variance and the ICC to compute the among-mouse ($\\sigma^2_\\alpha$) and among-cell ($\\sigma^2_\\varepsilon$) variances\n3. Use the among-mouse variance and the observed difference between treatment means to create fake mouse means with five mice per treatment and an expected difference between treatment means equal to the observed difference.\n4. Use the among-cell variance to create 1500 values per mouse (the average number of cells per mouse in the actual experiment) -- these values are random \"error\" around each mouse mean.\n5. Compute the mean value for each mouse\n6. Do a *t*-test\n7. Save the *t*-value\n8. Save the *p*-value\n9. Repeat 2-8 2000 times\n10. Compute the Power of the modified experimental design at the specified ICC using the 2000 *p*-values\n11. Compute the expected *p*-value for this ICC by\n  * Compute the mean of the 2000 *t*-values\n  * Compute the *p*-value from the averaged *t*-value\n12. Change the ICC to the next higher ICC in the list and repeat 2-11.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_to_p <- function(t){\n  p <- 2 * pt(-abs(t), df = n * 2 - 2, lower.tail = TRUE)\n  return(p)\n}\n\nset.seed(1)\nn_reps <- 2000\nn <- 5\nn_ss <- 1500\nsigma_total <- summary(m1_teff)$sigma # estimated SD for TEFF\ndelta <- .219 # observed difference for TEFF\nicc_vec <- c(0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.75)\nt <- numeric(n_reps)\ntable_out <- data.table(NULL)\n#sigma_a^2: the variance among mice\n#sigma_e^2: the error variance (within mice)\nfor(sim_i in 1:length(icc_vec)){\n  icc <- icc_vec[sim_i]\n  # icc = sigma_a^2/sigma_total^2\n  sigma_a <- sqrt(icc * sigma_total^2)\n  # sigma_total^2 = sigma_a^2 + sigma_e^2\n  sigma_e <- sqrt(sigma_total^2 - sigma_a^2)\n  for(rep_i in 1:n_reps){\n    tngfr_means <- rnorm(n, sd = sigma_a) \n    fox_means <- rnorm(n, sd = sigma_a) + delta \n    # slow\n    tngfr <- rnorm(n * n_ss, mean = rep(tngfr_means, each = n_ss), sd = sigma_e) |>\n      matrix(nrow = n_ss, ncol = n) |>\n      apply(2, mean)\n    fox <- rnorm(n * n_ss, mean = rep(fox_means, each = n_ss), sd = sigma_e) |>\n      matrix(nrow = n_ss, ncol = n) |>\n      apply(2, mean)\n    # fast shortcut since the estimated mean will be so close to true mean\n    # tngfr <- tngfr_means\n    # fox <- fox_means\n\n    t[rep_i] <- t.test(tngfr, fox, var.equal = TRUE)$statistic\n  }\n  p <- t_to_p(t)\n  table_out <- rbind(\n    table_out,\n    data.table(\n      icc = icc,\n      t = mean(t),\n      power = sum(p < 0.05)/n_reps\n    )\n  )\n  \n}\n\n\ntable_out[, p := 2 * pt(t, df = n * 2 - 2, lower.tail = TRUE)]\n\ngg1 <- ggplot(data = table_out,\n              aes(x = icc,\n                  y = p)) +\n  geom_line() +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n  theme_pubr()\ngg2 <- ggplot(data = table_out,\n              aes(x = icc,\n                  y = power)) +\n  geom_line() +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\") +\n  theme_pubr()\nplot_grid(gg1, gg2, ncol = 2, labels = \"AUTO\")\n```\n\n::: {.cell-output-display}\n![](FOXO1-is-a-master-regulator-of-memory-programming-in-CAR-T-cells_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nPanel A shows the expected, statistically valid *p*-value for the experimental design over a range of among-mouse variation relative to the total variation (the ICC). The modeling suggests that, given the observed difference, a modified experiment with known mouse ID for each cell would rarely observe small *p*-values unless the ICC were pretty small (less than about 0.25).\n\nPanel B shows the power of a modified experimental design with known mouse ID given different amounts of among-mouse variation relative to the total variation (the ICC) and using 5% as the significance level. Remember, Power is the probability of observing a *p*-value less than the set significance level. Typically, researchers want a power of 0.8 or higher to justify the time, cost and animal welfare of an experiment. The modeling suggests that a modified experimental design, with known mouse ID for each cell, and given the observed difference, would require a pretty small ICC (less than 0.15) in order to have good power.\n\nUnfortunately, we don't know the actual ICC and it's hard for me to make a reasonable guess, given my lack of familiarity with these kinds of data.\n\nAnd remember, the observed difference in expression levels seems kinda small.\n\n## Why the actual experimental design isn't worth the time, money, or cost to animal welfare\n\nGiven the actual (not modified to know mouse ID) experimental design, what is the rate of false positives (Type I error) - that is, the rate of significant *p*-values if there really were no effect of treatment? Like the power above, this depends on the relative amounts of among-mice and among-cell variance.\n\nAlgorithm:\n\n1. Start with the lowest ICC in a pre-specified list of ICCs that range between 0 and 1\n2. Use the observed total variance and the ICC to compute the among-mouse ($\\sigma^2_\\alpha$) and among-cell ($\\sigma^2_\\varepsilon$) variances\n3. Use the among-mouse variance to create fake mouse means with five mice per treatment and an expected difference between treatment means equal to zero.\n4. Use the among-cell variance to create 1500 values per mouse (the average number of cells per mouse in the actual experiment) -- these values are random \"error\" around each mouse mean.\n5. Compute the mean value for each mouse\n6. Do a *t*-test\n7. Save the *p*-value\n8. Repeat 2-7 2000 times\n9. Compute the Type I error rate of the experimental design at the specified ICC using the 2000 *p*-values\n10. Change the ICC to the next higher ICC in the list and repeat 2-9.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nn_reps <- 2000\nn <- 5\nn_ss <- 1500\nsigma_total <- summary(m1_teff)$sigma\nicc_vec <- c(0, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.75)\np <- numeric(n_reps)\ntable_out <- data.table(NULL)\n#sigma_a^2: the variance among mice\n#sigma_e^2: the error variance (within mice)\nfor(sim_i in 1:length(icc_vec)){\n  icc <- icc_vec[sim_i]\n  # icc = sigma_a^2/sigma_total^2\n  sigma_a <- sqrt(icc * sigma_total^2)\n  # sigma_total^2 = sigma_a^2 + sigma_e^2\n  sigma_e <- sqrt(sigma_total^2 - sigma_a^2)\n  for(rep_i in 1:n_reps){\n    mean_vec <- rep(rnorm(n, sd = sigma_a), each = n_ss)\n    samp_1 <- rnorm(n * n_ss, mean = mean_vec, sd = sigma_e)\n    mean_vec <- rep(rnorm(n, sd = sigma_a), each = n_ss)\n    samp_2 <- rnorm(n * n_ss, mean = mean_vec, sd = sigma_e)\n    p[rep_i] <- t.test(samp_1, samp_2, var.equal = TRUE)$p.value\n  }\n  table_out <- rbind(\n    table_out,\n    data.table(\n      icc = icc,\n      Type_I = sum(p < 0.05)/n_reps\n    )\n  )\n  \n}\n\nggplot(data = table_out,\n       aes(x = icc,\n           y = Type_I)) +\n  geom_line() +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n  theme_pubr()\n```\n\n::: {.cell-output-display}\n![](FOXO1-is-a-master-regulator-of-memory-programming-in-CAR-T-cells_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe plot shows that at effectively any ICC not super close to zero, the Type I error rates are elevated and this elevation is extreme at even very small ICC -- at an ICC of 0.005, this rate is 51%! At any biologically realistic ICC, the experimental design will result in significant *p*-values the majority of the time **when the true treatment effect is zero**!\n\n## Published Methods, cut and pasted from the article\n\nTo determine whether FOXO1 was also capable of increasing the activ- ity of CAR T cells against solid tumours, we infused tNGFR or FOXO1OE HER2.BBζ CAR T cells into 143B osteosarcoma-bearing NSG mice.\n\nTo generate single-cell RNA-seq libraries of tumour-infiltrating CAR T cells, Her2+ tumours were collected from five mice per condition, and human CD45+ cells were isolated by NGFR selection as described above (see ‘Cell selection’). Tumour-infiltrating CAR T cells were further purified by sorting human CD3+ TILs from each isolate using a Cytek Aurora Cell Sorter. A total of 20,000 CAR TILs were sorted from each tumour and pooled across five mice per group. Cells were barcoded and sequencing libraries were generated using the 10X Chromium Next GEM Single Cell 3’ v.3.1 kit (10X Genomics) according to the manufacturer’s instructions. Libraries were sequenced at the CHOP High Throughput Sequencing Core on an Illumina NovaSeq 6000 with an average read depth of 50,000 reads per cell.\n\nGene set scores for Teff, TRM and Treg cell subtypes were calculated with AddModuleScore (Seurat), using curated gene lists from a previous study58 (Extended Data Fig. 9g–i). AddModuleScore was also used to calculate a per-cell FOXO1 transcriptional activity score, using the top 100 upregulated genes in CD8+ HA.28ζ CAR T cells overexpressing FOXO1 versus tNGFR (Fig. 2). \n",
    "supporting": [
      "FOXO1-is-a-master-regulator-of-memory-programming-in-CAR-T-cells_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}